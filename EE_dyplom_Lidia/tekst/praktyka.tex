W celu obrazowego porównania obu metod należy przygotować program w języku Python, który zmierzy czas wykonywania obliczeń, wyznaczy współczynniki nachylenia i wyrazy wolny dla każdej z metod oraz przedstawi wyniki na wykresie~\cite{amit2021}~\cite{mark2022}~\cite{luciano2015}.


\section{Kod źródłowy Theil-Sen}

Program realizuje obliczenia za pomocą algorytmu Theil-Sen, wyznaczając współczynnik nachylenia i wyraz wolny. Następnie generuje wykres, na którym przedstawione są dane wejściowe oraz dopasowana do nich linia regresji, umożliwiając wizualną ocenę działania estymatora.

\begin{lstlisting}[language=Python,
caption={Program Theil-Sen},
label={lst:hellopy}]
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

\end{lstlisting}

Na listingu 1 importowane są potrzebne biblioteki: NumPy do operacji numerycznych, Matplotlib do tworzenia wykresów oraz mean\_squared\_error do obliczania błędu średniokwadratowego (MSE), który jest miarą stosowaną do oceny jakości dopasowania modelu do danych. 

\begin{lstlisting}[language=Python,
caption={Program Theil-Sen},
label={lst:hellopy}]
def mediana(tablica):
tablica_posortowana = np.sort(tablica)
dlugosc = len(tablica_posortowana)
if dlugosc % 2 == 0:
return (tablica_posortowana[dlugosc // 2 - 1] + tablica_posortowana[dlugosc // 2]) / 2.0
else:
return tablica_posortowana[dlugosc // 2]

\end{lstlisting}

Funkcja służy do obliczania mediany z tablicy. Na samym początku sortuje dane od najmniejszych do największych, wykorzystując funkcję np.sort(). Następnie zwraca wartości mediany. Jeśli zbiór elementów jest parzysty, funkcja zwraca średnią dwóch środkowych liczb, a jeśli jest nieparzysty, to środkową wartość.

\begin{lstlisting}[language=Python,
caption={Program Theil-Sen},
label={lst:hellopy}]

def regresja_theil_sen(x, y):
n = len(x)
nachylenia = []
wyrazy_wolne = []
\end{lstlisting}

Na Listing 3  zdefiniowana jest funkcja regresja\_theil\_sen, która implementuje estymator Theil-Sen. Funkcja rozpoczyna od obliczenia długości wektora x oraz inicjalizacji dwóch pustych list: nachylenia i wyrazy\_wolne. Listy te będą przechowywać odpowiednio wszystkie obliczone nachylenia i wyrazy wolne.

\begin{lstlisting}[language=Python,
caption={Program Theil-Sen},
label={lst:hellopy}]
for i in range(n):
    for j in range(i + 1, n):
        if x[i] != x[j]: 
        nachylenie = (y[j] - y[i]) / (x[j] - x[i])
        nachylenia.append(nachylenie)
 mediana_nachylenia = mediana(nachylenia)
\end{lstlisting}

Zostały zdefiniowane pętle for, w których obliczane są nachylenia każdej pary punktów (xi, xj) zgodnie ze wzorem regresji metodą Theil-Sena. Następnie, przy użyciu metody append(), obliczone wartości nachyleń są dodawane do listy. Po zakończeniu pętli, na podstawie zgromadzonych wartości, obliczana jest mediana nachyleń.

\begin{lstlisting}[language=Python,
caption={Program Theil-Sen},
label={lst:hellopy}]
for i in range(n):
    wyrazy_wolne.append(y[i] - mediana_nachylenia * x[i])
mediana_wyrazu = mediana(wyrazy_wolne)
wynik = {'nachylenie': mediana_nachylenia, 'wyraz_wolny': mediana_wyrazu}
    return wynik

\end{lstlisting}

Na tej samej zasadzie obliczany jest wyraz wolny. Zgromadzone wartości wyrazów wolnych są dodawane do listy, a następnie obliczana jest ich mediana. Na koniec zwracany jest wynik zawierający obliczone wartości nachylenia oraz wyrazu wolnego.

\begin{lstlisting}[language=Python,
caption={Program Theil-Sen},
label={lst:hellopy}]
x = np.random.randn(100, 1)
y = 3 * x.flatten() + 2 + np.random.randn(100) * 2
\end{lstlisting}

Ustawienie ziarna losowości zapewnia otrzymanie zawsze takiego samego punktu wyjścia, więc przy każdym uruchomieniu kodu generowane liczby będą identyczne. Co zapewni te same wyniki. Następnie stworzona zostaje tablica x zawierająca 100 losowych liczb w przedziale od 0 do 10 oraz tablica y, której każda z wartości jest wynikiem równania y = 3x + 2 z dodatkiem szumu (losowych odchyłek).

\begin{lstlisting}[language=Python,
caption={Program Theil-Sen},
label={lst:hellopy}]
wynik = regresja_theil_sen(x, y)  
y_przewidziane_theil_sen = przewidz(x, wynik)  
mse = mean_squared_error(y, y_przewidziane_theil_sen)

\end{lstlisting}

Zmienna wynik zawiera dopasowany model regresji Theil-Sen do danych wejściowych x i y. Na podstawie tego modelu przewidywane są wartości y dla każdego punktu x. Na koniec obliczany jest błąd średniokwadratowy (MSE), który ocenia jakość dopasowania modelu do rzeczywistych danych. Jest on wyrażony jako średnia kwadratów różnic między wartościami rzeczywistymi a wartościami przewidywanymi przez model.

\begin{lstlisting}[language=Python,
caption={Program Theil-Sen},
label={lst:hellopy}]
print("Metoda Theil-Sena:")
print(f"Nachylenie (wspolczynnik kierunkowy): {model_theil_sen.coef_[0]:.2f}")
print(f"Przesuniecie (punkt przeciecia z osia Y): {model_theil_sen.intercept_:.2f}")
print(f"Blad sredniokwadratowy (MSE): {mse:.2f}")

\end{lstlisting}

Kod wyświetla za pomocą funkcji print wartości współczynników regresji Theil-Sena, w tym nachylenie, przesunięcie oraz obliczony błąd średniokwadratowy (MSE). Wyniki są zaokrąglone do dwóch miejsc po przecinku.

\begin{lstlisting}[language=Python,
caption={Program Theil-Sen},
label={lst:hellopy}]

plt.figure(figsize=(10, 6))
plt.scatter(x, y, color='blue', label='Dane rzeczywiste', alpha=0.6)
plt.plot(x, y_pred, color='black', label='Regresja Theil-Sen', linewidth=2)
plt.xlabel('x')
plt.ylabel('y')
plt.title('Regresja metoda Theil-Sen')
plt.legend()
plt.grid(True)
plt.show()
\end{lstlisting}

W fragmencie kodu tworzony jest wykres, na którym przedstawiane są rzeczywiste dane, oraz linia regresji uzyskana za pomocą metody Theil-Sena. Rzeczywiste dane są reprezentowane przez niebieskie punkty, natomiast przewidywana linia regresji Theil-Sena jest zaznaczona czarną linią. Dodatkowo wykres zawiera opisy osi, tytuł oraz podziałkę, co ułatwia interpretację wyników.

\begin{figure}[h!]
\centering
\includegraphics[width=0.7\linewidth]{theil.png}
\caption{Wizualizacja metody Theil-Sen}
\label{rys:Wykres metody Theil-Sen}
\end{figure}

Po przeprowadzonych obliczeniach metodą Theil-Sen wyświetlany jest wynik nachylenia, wyrazu wolnego oraz błędu średniokwadratowego.

Nachylenie (współczynnik kierunkowy): 2.59

Przesunięcie (punkt przecięcia z osią Y): 2.13

Błąd średniokwadratowy (MSE): 3.81

\section{Kod źródłowy metody najmniejszych kwadratów}

Program realizuje obliczenia linii regresji metodą najmniejszych kwadratów (OLS), dopasowując ją tak, aby minimalizować różnice między danymi a modelem. Następnie generuje wykres, na którym przedstawione są punkty danych i dopasowana linia, co pozwala ocenić działanie metody.

\begin{lstlisting}[language=Python,
caption={Program metody najmniejszych kwadratów},
label={lst:hellopy}]
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

\end{lstlisting}

Na Listing 10 przedstawiono wykorzystanie modułu sklearn.linear\_model oraz klasy LinearRegression, która służy do przeprowadzenia regresji liniowej metodą najmniejszych kwadratów. Dodatkowo, do oceny jakości dopasowania modelu zastosowano błąd średniokwadratowy.
Wszystkie inne kroki w kodzie, takie jak dopasowanie modelu do danych, przewidywanie wartości czy wizualizacja wyników, pozostają bez zmian.

\begin{figure}[h!]
\centering
\includegraphics[width=0.7\linewidth]{kwadrat1.png}
\caption{Wizualizacja metody najmniejszych kwadratów}
\label{rys:enter-label}
\end{figure}
Po wykonaniu obliczeń metodą najmniejszych kwadratów wyznaczana jest wartości współczynnika nachylenia, wyrazu wolnego oraz  błędu średniokwadratowego.

Nachylenie (współczynnik kierunkowy): 2.78

Przesunięcie (punkt przecięcia z osią Y): 2.08

Błąd średniokwadratowy (MSE): 4.89






\section{Porównanie metod Thei-Sen i OLS}

\begin{lstlisting}[language=Python,
caption={Program dla obu metod},
label={lst:hellopy}]
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import TheilSenRegressor
from sklearn.metrics import mean_squared_error
import time

\end{lstlisting}

W tym przypadku zostanie wykorzystana już  gotowa biblioteka Theil-Sen z dodaną biblioteką 'time', która będzie odpowiedzialna za mierzenie czasu, co pozwoli na sprawdzenie, która z metod jest szybsza.

\begin{lstlisting}[language=Python,
caption={Program dla obu metod},
label={lst:hellopy}]
num_outliers = 100
indices = np.random.choice(range(500), num_outliers, replace=False)
x[indices] = x[indices] + np.random.uniform(2, 5, (num_outliers, 1))
y[indices] = y[indices] + np.random.uniform(-10, 10, num_outliers)

\end{lstlisting}
Użyta tu komenda służy do wyboru losowych punktów odstających oraz zwiększenia wartości x dla punktów.

\begin{lstlisting}[language=Python,
caption={Program dla obu metod},
label={lst:hellopy}]
start_time_theil_sen = time.perf_counter()
model_theil_sen = TheilSenRegressor()
model_theil_sen.fit(x, y)
y_przewidziane_theil_sen = model_theil_sen.predict(X)
end_time_theil_sen = time.perf_counter()
time_theil_sen = end_time_theil_sen - start_time_theil_sen
\end{lstlisting}

Na listingu 13 dokonywany jest pomiar czasu trwania obliczeń dla metody  Theil-Sen. Proces ten polega na zainicjowaniu modelu regresji oraz dopasowaniu go do danych. Zapisujemy czas rozpoczęcia pomiaru, a następnie wykonujemy wszystkie operacje związane z dopasowaniem. Na końcu mierzymy czas zakończenia obliczeń, a różnica między tymi dwoma momentami daje czas trwania obliczeń dla metody.

\subsection{Porównanie wyników}

\begin{figure}[h!]
\centering
\includegraphics[width=0.7\linewidth]{THKW.png}
\caption{Wizualizacja obu metod}
\label{fig:enter-label}
\end{figure}

\begin{table}[!h]
\centering
\begin{tabular}{p{8 cm} |c|c}
& Theil-Sen & OLS\\\hline
Nachylenie (współczynnik kierunkowy) & 2.81 & 1.87\\\hline
Przesunięcie (współczynnik przesunięcia z osią Y) & 1.87 & 1.51\\\hline
Czas obliczeń [s] & 0.2806 & 0.0003\\\hline
Błąd średniokwadratowy (MSE) & 4.68 & 4.89\\\hline

\end{tabular}
\caption{\label{tab:zjawiska2}Porównanie wyników}
\end{table}

W tym przypadku celowo jest dodane dużo punktów oraz wartości odstającej, by lepiej zaobserwować różnicę w obu metodach. Z tabeli i wykresu można wysnuć wnioski, iż metoda Theil-Sen (linia czerwona) poprawniej dopasowała linię regresji do podanych punktów w porównaniu do metody najmniejszych kwadratów (czarna prosta). Za to w tej drugiej wynik udało się uzyskać w krótszym czasie. Co zgadza się z początkowymi założeniami odnośnie do obu metod~\cite{hristo2019}~\cite{james2015}.

Metoda Theil-Sena posiada szereg zalet, które czynią ją atrakcyjną alternatywą w stosunku do innych technik regresji, szczególnie w kontekście danych zawierających wartości odstające. Dzięki swojej odporności na wpływ punktów odstających metoda ta może zapewniać dokładniejsze wyniki w przypadkach, gdy tradycyjne metody, takie jak regresja najmniejszych kwadratów, mogą być podatne na zniekształcenia wynikające z takich anomalii. Z tego powodu implementacja estymatora Theil-Sena na mikrokontrolerze STM32 może okazać się korzystnym rozwiązaniem, szczególnie w aplikacjach, w których dane wejściowe charakteryzują się dużą zmiennością lub obecnością wartości odstających.